{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a0c1a3-f5f6-4b7b-a230-a56c148c881e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #eee3d3\">\n",
    "<h1> 4-dimensionality_reduction.ipynb </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa435a7-4a1a-41e2-9523-bd2651ffca15",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### The purpose of this notebook is to reduce the dimension of our peak table :\n",
    "\n",
    "One main challenge in metabolomics data analysis is dealing with high dimension data, e.g. for a peak table $(n,p)$, having $p > n$ (more features than samples). It could be a problem for downstream analysis.\n",
    "\n",
    "To reduce the dimensionnality, you can use :\n",
    "- feature selection: find a subset of input features\n",
    "- feature extraction: project high-dimensional space into a space of fewer dimensions\n",
    "\n",
    "_Hint : methods that can be tested (or not ?) $\\rightarrow$ Principal Component Analysis (PCA), Partial Least Squares (PLS), Canonical Correlation Analysis (CCA), Autoencoder, ..._\n",
    "\n",
    "_Autoencoder is a type of artificial neural network, part of deep learning, you can test this method at the very end of the project if you still have time and interest in that (__huge bonus if you manage to make it work, but do it only if you have time left, the main objective of this project is to find potential biomarkers__)_\n",
    "\n",
    "---\n",
    "\n",
    "Import a peak table that you previously imputed (thus has no more missing values) and treated (transformation and/or scaling and/or normalisation).\n",
    "\n",
    "Same as before, think about quantitative/qualitative/graphic ways to present the different method outputs !\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec086d0",
   "metadata": {},
   "source": [
    "### Very nice --> https://cimcb.github.io/MetabWorkflowTutorial/Tutorial1.html\n",
    "\n",
    "**Voir les quelques notes que j'ai mise sur le drive**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4ae62",
   "metadata": {},
   "source": [
    "## 1) PCA testing (not done yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cimcb_lite as cb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-1]) + '/bin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import normalisation_scaling_functions as nsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used the mean normalization and Bayesian imputation (can use any other, I chosed randomly)\n",
    "path_peakTable = '/'.join(os.getcwd().split('/')[:-1]) + '/data/peakTable/original_peak_table/peakTable_HILIC_POS.csv'\n",
    "peakTable_HILIC_POS = pd.read_csv(path_peakTable, sep=',', decimal='.', na_values='NA')\n",
    "peakTable_HILIC_POS.head()\n",
    "\n",
    "data = pd.read_csv('/'.join(os.getcwd().split('/')[:-1]) + '/data/peakTable/imputed_peak_tables/X_python_MICE_BayesianRidge.csv')\n",
    "data_nm = nsf.normPeakTable(data, 'mean_normalisation', based='samples')\n",
    "data_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ed392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41409652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Extract X matrix\n",
    "names = peak['Name']\n",
    "x = data[names].values\n",
    "x = np.log(x)\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "# Create and fit PCA\n",
    "pca = PCA(n_components=2)\n",
    "scores = pca.fit_transform(x)\n",
    "label = data['SampleType']\n",
    "\n",
    "# Split scores into sample and QC\n",
    "Sample_scores = scores[label == 'Sample',:]\n",
    "QC_scores = scores[label == 'QC',:]\n",
    "\n",
    "# Plot Sample score and QC score\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "h1 = plt.scatter(Sample_scores[:,0],Sample_scores[:,1],edgecolors='Black', facecolors='Green',s=100,alpha=0.5)\n",
    "h2 = plt.scatter(QC_scores[:,0],QC_scores[:,1], edgecolors='Black', facecolors='Red',s=100,alpha=0.5)\n",
    "\n",
    "# Add legend, labels, and title\n",
    "plt.legend((h1,h2),('Sample','QC'),fontsize=15)\n",
    "plt.xlabel('PC1', fontsize=15)\n",
    "plt.ylabel('PC2', fontsize=15)\n",
    "plt.title('Quality Control PCA plot',fontsize=20)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb4775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6303e078",
   "metadata": {},
   "source": [
    "###  Creating PCA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58baabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose = data_nm.T\n",
    "pca = PCA(n_components=5)\n",
    "scores = pca.fit(transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e06c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pca.fit_transform(data_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b363af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "h = plt.scatter(scores[:,3],scores[:,1],edgecolors='Black', facecolors='Black',s=10,alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumo_type=peakTable_HILIC_POS[\"TypTumo\"]\n",
    "tumo_type=tumo_type.fillna(\"Non-case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=peakTable_HILIC_POS[\"Groups\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3180b9a",
   "metadata": {},
   "source": [
    "###   Separation en incedent et noncase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_incedent = scores[groups == 'Incident',:]\n",
    "scores_noncase = scores[groups == 'Non-case',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Sample score and QC score\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "h1 = plt.scatter(scores_incedent[:,0],scores_incedent[:,1],edgecolors='Black', facecolors='Green',s=100)\n",
    "h2 = plt.scatter(scores_noncase[:,0],scores_noncase[:,1], edgecolors='Black', facecolors='Blue',s=100)\n",
    "\n",
    "# Add legend, labels, and title\n",
    "plt.legend((h1,h2),('Incident','Non-case'),fontsize=15)\n",
    "plt.xlabel('PC1', fontsize=15)\n",
    "plt.ylabel('PC2', fontsize=15)\n",
    "plt.title('Quality Control PCA plot',fontsize=20)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081d2c9",
   "metadata": {},
   "source": [
    "###  Non case HCC Wid and HCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and scale the metabolite data from the dataTable \n",
    "\n",
    "X = data_nm.values                      # Extract X matrix from dataTable using peaklist\n",
    "#Xlog = np.log10(X)                                  # Log scale (base-10)\n",
    "#Xscale = cb.utils.scale(Xlog, method='auto')        # methods include auto, range, pareto, vast, and level\n",
    "#Xknn = cb.utils.knnimpute(Xscale, k=3)              # missing value imputation (knn - 3 nearest neighbors)\n",
    "\n",
    "#print(\"Xknn: {} rows & {} columns\".format(*Xknn.shape))\n",
    "\n",
    "cb.plot.pca(X,\n",
    "            pcx=1,                                                  # pc for x-axis\n",
    "            pcy=5,                                                  # pc for y-axis\n",
    "            group_label=tumo_type)                    # labels for Hover in PCA loadings plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0db75",
   "metadata": {},
   "source": [
    "## 2) PLS (Partial Least Square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_peakTable = '/'.join(os.getcwd().split('/')[:-1]) + '/data/peakTable/original_peak_table/peakTable_HILIC_POS.csv'\n",
    "peakTable = pd.read_csv(path_peakTable, sep=',', decimal='.', na_values='NA')\n",
    "first_cols = peakTable.iloc[:, ['variable' not in col for col in peakTable.columns]]\n",
    "first_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([first_cols, data_nm], axis=1)\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35721745-942a-454d-9b1f-034b36675c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary Y vector for stratifiying the samples\n",
    "outcomes = full_data['TypTumo']                                  # Column that corresponds to Y class (should be 2 groups)\n",
    "Y = [1 if outcome == 'HCC' or outcome == 'HCC_Wide' else 0 for outcome in outcomes]       # Change Y into binary (GC = 1, HE = 0)  \n",
    "Y = np.array(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe3797-a8bd-4dd0-85b7-1bc9e6cab711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split full_data and Y into train and test (with stratification)\n",
    "dataTrain, dataTest, Ytrain, Ytest = train_test_split(full_data, Y, test_size=0.25, stratify=Y,random_state=10)\n",
    "\n",
    "print(\"DataTrain = {} samples with {} positive cases.\".format(len(Ytrain),sum(Ytrain)))\n",
    "print(\"DataTest = {} samples with {} positive cases.\".format(len(Ytest),sum(Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4867a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and scale the metabolite data from the dataTable\n",
    "\n",
    "peaklist = peakTable.columns[5:]                          # Set peaklist to the metabolite names in the peakTableClean\n",
    "XT = dataTrain[peaklist]                                    # Extract X matrix from DataTrain using peaklist\n",
    "#XTlog = np.log(XT)                                          # Log scale (base-10)\n",
    "XTscale = cb.utils.scale(XT, method='auto')              # methods include auto, pareto, vast, and level\n",
    "XTknn = cb.utils.knnimpute(XTscale, k=3)                    # missing value imputation (knn - 3 nearest neighbors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3deaab-6113-4c61-9f9a-94cd751679af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalise cross_val kfold (stratified) \n",
    "cv = cb.cross_val.kfold(model=cb.model.PLS_SIMPLS,                   # model; we are using the PLS_SIMPLS model\n",
    "                        X=XTknn,                                 \n",
    "                        Y=Ytrain,                               \n",
    "                        param_dict={'n_components': [1,2,3,4,5,6]},  # The numbers of latent variables to search                \n",
    "                        folds=5,                                     # folds; for the number of splits (k-fold)\n",
    "                        bootnum=100)                                 # num bootstraps for the Confidence Intervals\n",
    "\n",
    "# run the cross validation\n",
    "cv.run()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39795887-90ad-4732-81a7-a41ab05cfac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dcba12-4e2a-4d30-96ec-81b72692a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no idea how to interpret these plots :/ sorrrrrryyyyyyyy jpp c'est flou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb889a-a4e9-4737-b157-b1c5f368d8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2defab3d-c66f-45e6-a632-97508d6737e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9d5aa-bed4-47fc-9beb-0a49667524d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a357946-2c43-4bce-9939-3d4d7c8e7be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
